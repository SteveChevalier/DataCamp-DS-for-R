# --------------------------------------------
# ---------- 14_Working with Dates and Times in ----
# --------------------------------------------
```{r}
# done;  install.packages("anytime")
library(readr); library(anytime)
```

```{r}
# ------- Dates and Times in R ----------
# The date R 3.0.0 was released
x <- "2013-04-03"
# Examine structure of x
str(x)
# Use as.Date() to interpret x as a date
x_date <- as.Date(x)
# Examine structure of x_date
str(x_date)
# Store April 10 2014 as a Date
april_10_2014 <- as.Date("2014-04-10")
str(april_10_2014)
```

```{r}
# Load the readr package
library(readr)
# Use read_csv() to import rversions.csv
releases <- read_csv("rversions.csv")
# Examine the structure of the date column
str(releases)
# Load the anytime package
library(anytime)
# Various ways of writing Sep 10 2009
sep_10_2009 <- c("September 10 2009", "2009-09-10", "10 Sep 2009", "09-10-2009")
# Use anytime() to parse sep_10_2009
anytime(sep_10_2009)

# Load the readr package
library(readr)
# Use read_csv() to import rversions.csv
releases <- read_csv("rversions.csv")
# Examine the structure of the date column
str(releases$date)
# Load the anytime package
library(anytime)
# Various ways of writing Sep 10 2009
sep_10_2009 <- c("September 10 2009", "2009-09-10", "10 Sep 2009", "09-10-2009")
# Use anytime() to parse sep_10_2009
str(anytime(sep_10_2009))
```

library(ggplot2)
# Set the x axis to the date column
ggplot(releases, aes(x = date, y = type)) +
  geom_line(aes(group = 1, color = factor(major)))
# Limit the axis to between 2010-01-01 and 2014-01-01
ggplot(releases, aes(x = date, y = type)) +
  geom_line(aes(group = 1, color = factor(major))) +
  xlim(as.Date("2010-01-01"), as.Date("2014-01-01"))
# Specify breaks every ten years and labels with "%Y"
ggplot(releases, aes(x = date, y = type)) +
  geom_line(aes(group = 1, color = factor(major))) +
  scale_x_date(date_breaks = "10 years", date_labels = "%Y")

# Find the largest date
last_release_date <- max(releases$date)
# Filter row for last release
last_release <- filter(releases, releases$date == last_release_date)
# Print last_release
last_release
# How long since last release?
Sys.Date() - max(as.Date(releases$date))

# Use as.POSIXct to enter the datetime 
as.POSIXct("2010-10-01 12:12:00")
# Use as.POSIXct again but set the timezone to `"America/Los_Angeles"`
as.POSIXct("2010-10-01 12:12:00", tz = "America/Los_Angeles")
# Use read_csv to import rversions.csv
releases <- read_csv("rversions.csv")
# Examine structure of datetime column
str(releases$datetime)

# Import "cran-logs_2015-04-17.csv" with read_csv()
logs <- read_csv("cran-logs_2015-04-17.csv")
# Print logs
logs
# Store the release time as a POSIXct object
release_time <- as.POSIXct("2015-04-16 07:13:33", tz = "UTC")
# When is the first download of 3.2.0?
logs %>% 
  filter(datetime > release_time,
         r_version == "3.2.0")
# Examine histograms of downloads by version
ggplot(logs, aes(x = datetime)) +
  geom_histogram() +
  geom_vline(aes(xintercept = as.numeric(release_time)))+
  facet_wrap(~ r_version, ncol = 1)



# ------- Parsing and Manipulating Dates and Times with lubridate
library(lubridate);library(readr);library(dplyr);library(ggplot2)
# Parse x 
x <- "2010 September 20th" # 2010-09-20
ymd(x)
# Parse y 
y <- "02.01.2010"  # 2010-01-02
dmy(y)
# Parse z 
z <- "Sep, 12th 2010 14:00"  # 2010-09-12T14:00
mdy_hm(z)

?parse_date_time

# Specify an order string to parse x
x <- "Monday June 1st 2010 at 4pm"
parse_date_time(x, orders = 'amdyIp')

# Specify order to include both "mdy" and "dmy"
two_orders <- c("October 7, 2001", "October 13, 2002", "April 13, 2003", 
                "17 April 2005", "23 April 2017")
parse_date_time(two_orders, orders = c("mdy", "dmy"))

# Specify order to include "dOmY", "OmY" and "Y"
short_dates <- c("11 December 1282", "May 1372", "1253")
parse_date_time(short_dates, orders = c("dOmY", "OmY", "Y"))

# Import CSV with read_csv()
akl_daily_raw <- read_csv("akl_weather_daily.csv")
# Print akl_daily_raw
akl_daily_raw
# Parse date 
akl_daily <- akl_daily_raw %>%
  mutate(date = ymd(date))
# Print akl_daily
akl_daily
# Plot to check work
ggplot(akl_daily, aes(x = date, y = max_temp)) +
  geom_line() 

# Import "akl_weather_hourly_2016.csv"
akl_hourly_raw <- read_csv("akl_weather_hourly_2016.csv")
# Print akl_hourly_raw
akl_hourly_raw
# Use make_date() to combine year, month and mday 
akl_hourly  <- akl_hourly_raw  %>% 
  mutate(date = make_date(year = year, month = month, day = mday))
# Parse datetime_string 
akl_hourly <- akl_hourly  %>% 
  mutate(
    datetime_string = paste(date, time, sep = "T"),
    datetime = ymd_hms(datetime_string)
  )
# Print date, time and datetime columns of akl_hourly
akl_hourly %>% select(date, time, datetime)
# Plot to check work
ggplot(akl_hourly, aes(x = datetime, y = temperature)) +
  geom_line()

# Examine the head() of release_time
head(release_time)
# Examine the head() of the months of release_time
head(month(release_time))
# Extract the month of releases 
month(release_time) %>% table()
# Extract the year of releases
year(release_time) %>% table()
# How often is the hour before 12 (noon)?
mean(hour(release_time) < 12)
# How often is the release in am?
mean(am(release_time))

# Use wday() to tabulate release by day of the week
wday(releases$datetime) %>% table()
# Add label = TRUE to make table more readable
wday(releases$datetime, label = T) %>% table()
# Create column wday to hold labelled week days
releases$wday <- wday(releases$datetime, label = T)
# Plot barchart of weekday by type of release
ggplot(releases, aes(wday)) +
  geom_bar() +
  facet_wrap(~ type, ncol = 1, scale = "free_y")

library(ggplot2)
library(dplyr)
library(ggridges)
# Add columns for year, yday and month
akl_daily <- akl_daily %>%
  mutate(
    year = year(date),
    yday = yday(date),
    month = month(date, label = TRUE))
# Plot max_temp by yday for all years
ggplot(akl_daily, aes(x = yday, y = max_temp)) +
  geom_line(aes(group = year), alpha = 0.5)
# Examine distribtion of max_temp by month
ggplot(akl_daily, aes(x = max_temp, y = month, height = ..density..)) +
  geom_density_ridges(stat = "density")

# Create new columns hour, month and rainy
akl_hourly <- akl_hourly %>%
  mutate(
    hour = hour(datetime),
    month = month(datetime, label = TRUE),
    rainy = weather == "Precipitation"
  )

# Filter for hours between 8am and 10pm (inclusive)
akl_day <- akl_hourly %>% 
  filter(hour >= 8, hour <= 22)
# Summarise for each date if there is any rain
rainy_days <- akl_day %>% 
  group_by(month, date) %>%
  summarise(
    any_rain = any(rainy)
  )
# Summarise for each month, the number of days with rain
rainy_days %>% 
  summarise(
    days_rainy = sum(any_rain)
  )

# All three take a unit argument which specifies the resolution of rounding. 
  # You can specify "second", "minute", "hour", "day", "week", "month", "bimonth", 
  #   "quarter", "halfyear", or "year". Or, you can specify any multiple of those units, 
  #   e.g. "5 years", "3 minutes" etc.

r_3_4_1 <- ymd_hms("2016-05-03 07:13:28 UTC")
# Round down to day
floor_date(r_3_4_1, unit = "day")
# Round to nearest 5 minutes
round_date(r_3_4_1, unit = "5 minutes")
# Round up to week 
ceiling_date(r_3_4_1, unit = "week")
# Subtract r_3_4_1 rounded down to day
r_3_4_1 - floor_date(r_3_4_1, unit = "day")

# Create day_hour, datetime rounded down to hour
akl_hourly <- akl_hourly %>%
  mutate(
    day_hour = floor_date(datetime, unit = "hour")
  )
# Count observations per hour  
akl_hourly %>% 
  count(day_hour) 
# Find day_hours with n != 2  
akl_hourly %>% 
  count(day_hour) %>%
  filter(n != 2) %>% 
  arrange(desc(n))

# ------- Arithmetic with Dates and Times
# difftime() takes an argument units which specifies the units for the difference. 
#   Your options are "secs", "mins", "hours", "days", or "weeks".
# The date of landing and moment of step
date_landing <- mdy("July 20, 1969")
moment_step <- mdy_hms("July 20, 1969, 02:56:15", tz = "UTC")
# How many days since the first man on the moon?
difftime(today(),date_landing, units = "days")
# How many seconds since the first man on the moon?
difftime(now(), moment_step, units = "secs")

# Three dates
mar_11 <- ymd_hms("2017-03-11 12:00:00", 
                  tz = "America/Los_Angeles")
mar_12 <- ymd_hms("2017-03-12 12:00:00", 
                  tz = "America/Los_Angeles")
mar_13 <- ymd_hms("2017-03-13 12:00:00", 
                  tz = "America/Los_Angeles")
# Difference between mar_13 and mar_12 in seconds
difftime(mar_13, mar_12, units = "secs")
# Difference between mar_12 and mar_11 in seconds
difftime(mar_12, mar_11, units = "secs")

# Add a period of one week to mon_2pm
mon_2pm <- dmy_hm("27 Aug 2018 14:00")
mon_2pm + days(7)
# Add a duration of 81 hours to tue_9am
tue_9am <- dmy_hm("28 Aug 2018 9:00")
tue_9am + dhours(81)
# Subtract a period of five years from today()
today() - dyears(5)
# Subtract a duration of five years from today()
today() - years(5)

# For example, to create a duration of three days and three hours you could do: 
#   ddays(3) + dhours(3), or 3*ddays(1) + 3*dhours(1) or even 3*(ddays(1) + dhours(1)).

# Time of North American Eclipse 2017
eclipse_2017 <- ymd_hms("2017-08-21 18:26:40")
# Duration of 29 days, 12 hours, 44 mins and 3 secs
synodic <- ddays(29) + dhours(12) + dminutes(44) + dseconds(3)
# 223 synodic months
saros <- synodic * 223
# Add saros to eclipse_2017
eclipse_2017 + saros

# Add a period of 8 hours to today
today_8am <- today() + dhours(8)
# Sequence of two weeks from 1 to 26
every_two_weeks <- 1:26 * weeks(2)
# Create datetime for every two weeks for a year
today_8am + every_two_weeks

# A sequence of 1 to 12 periods of 1 month
  # But use these operators with caution, unlike + and -, 
  # you might not get x back from x %m+% months(1) %m-% months(1). 
  # If you'd prefer that the date was rolled forward check out 

# add_with_rollback() which has roll_to_first argument. 
month_seq <- 1:12 * months(1)
# Add 1 to 12 months to jan_31
jan_31 + month_seq
# Replace + with %m+%
jan_31 %m+% month_seq
# Replace + with %m-%
jan_31 %m-% month_seq

# Intervals; use when you have a start and end
# Periods; when you are interested in human units
# Duration; if you are interested in seconds elapsed
  # You can create an interval by using the operator %--% with two datetimes. 
  #   For example ymd("2001-01-01") %--% ymd("2001-12-31") creates an interval for the year of 2001.
  # Once you have an interval you can find out certain properties like its start, 
  #   end and length with int_start(), int_end() and int_length() respectively.

# Print monarchs
monarchs
# Create an interval for reign
monarchs <- monarchs %>%
  mutate(reign = from %--% to) 
# Find the length of reign, and arrange
monarchs %>%
  mutate(length = int_length(reign)) %>% 
  arrange(desc(length)) %>%
  select(name, length, dominion)

# The operator %within% tests if the datetime (or interval) on the left hand side 
# is within the interval of the right hand side. For example, 
# if y2001 is the interval covering the year 2001,
# example in text
library(lubridate)
y2001 <- ymd("2001-01-01") %--% ymd("2001-12-31")
ymd("2001-03-30") %within% y2001
ymd("2002-03-30") %within% y2001

# Practice to find out which monarchs saw Halley's comet around 1066.
# Print halleys
halleys
# New column for interval from start to end date
halleys <- halleys %>% 
  mutate(visible = start_date %--% end_date)
# The visitation of 1066
halleys_1066 <- halleys[14, ] 
# Monarchs in power on perihelion date
monarchs %>% 
  filter( halleys_1066$perihelion_date %within% reign ) %>%
  select(name, from, to, dominion)
# Monarchs whose reign overlaps visible time
monarchs %>% 
  filter(int_overlaps(halleys_1066$visible,reign)) %>%
  select(name, from, to, dominion)

# New columns for duration and period
monarchs <- monarchs %>%
  mutate(
    duration = as.duration(reign),
    period = as.period(reign) 
  )
# Examine results    
monarchs %>%
  select(name, duration, period)

# ------- Problems in practice
Sys.timezone()
OlsonNames() # timezones
length(OlsonNames())
force_tz() # change time zone
view_tz() # view with a diff tz than stored (good for compare across tzs)

# Game2: CAN vs NZL in Edmonton
game2 <- mdy_hm("June 11 2015 19:00")
# Game3: CHN vs NZL in Winnipeg
game3 <- mdy_hm("June 15 2015 18:30")
# Set the timezone to "America/Edmonton"
game2_local <- force_tz(game2, tzone = "America/Edmonton")
game2_local
# Set the timezone to "America/Winnipeg"
game3_local <- force_tz(game3, tzone = "America/Winnipeg")
game3_local
# How long does the team have to rest?
as.period(game2_local %--% game3_local)

now <- now()
with_tz(now, "America/Los_Angeles") - with_tz(now,  "Pacific/Auckland")

# What time is game2_local in NZ?
with_tz(game2_local, tzone = "Pacific/Auckland")
# What time is game2_local in Corvallis, Oregon?
with_tz(game2_local, tzone = "America/Los_Angeles")
# What time is game3_local in NZ?
with_tz(game3_local, tzone = "Pacific/Auckland")

# Examine datetime and date_utc columns
head(akl_hourly$datetime)
head(akl_hourly$date_utc)

# Force datetime to Pacific/Auckland
akl_hourly <- akl_hourly %>%
  mutate(datetime = force_tz(datetime, tzone = "Pacific/Auckland"))
# Reexamine datetime
head(akl_hourly$datetime)
# Are datetime and date_utc the same moments
table(akl_hourly$datetime - akl_hourly$date_utc)


# Import auckland hourly data 
akl_hourly <- read_csv("akl_weather_hourly_2016.csv")
# Examine structure of time column
str(akl_hourly)
str(akl_hourly$time)
# Examine head of time column
head(akl_hourly$time)
# A plot using just time
ggplot(akl_hourly, aes(x = time, y = temperature)) +
  geom_line(aes(group = make_date(year, month, mday)), alpha = 0.2)

library(microbenchmark)
library(fasttime)
# Examine structure of dates
str(dates)
# Use fastPOSIXct() to parse dates
fastPOSIXct(dates) %>% str("%Y-%m-%d")
# Compare speed of fastPOSIXct() to ymd_hms()
microbenchmark(
  ymd_hms = ymd_hms(dates),
  fasttime = fastPOSIXct(dates),
  times = 20)

# Head of dates
head(dates)
# Parse dates with fast_strptime
fast_strptime(dates, 
              format = "%Y-%m-%dT%H:%M:%SZ") %>% str()
# Comparse speed to ymd_hms() and fasttime
microbenchmark(
  ymd_hms = ymd_hms(dates),
  fasttime = fastPOSIXct(dates),
  fast_strptime = fast_strptime(dates, 
                                format = "%Y-%m-%dT%H:%M:%SZ"),
  times = 20)

# Create a stamp based on "Sep 20 2017"
date_stamp <- stamp("Sep 20 2017")
# Print date_stamp
date_stamp
# Call date_stamp on today()
date_stamp(today())
# Create and call a stamp based on "09/20/2017"
stamp("09/20/2017")(today())
# Use string finished for stamp()
stamp(finished)(today())
